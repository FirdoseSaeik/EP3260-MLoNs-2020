{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports from libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import resource\n",
    "import time\n",
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "import cvxpy\n",
    "from multiprocessing import Process, Pipe\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "## NOTE: Install keras --------------------------------------------------------------------\n",
    "###------------------- keras imports for the dataset and neural network --------------------##\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing of data\n",
    "# Load data from keras:\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Reshape data for building the input vector from the 28x28 pixels\n",
    "X_train = ... #complete \n",
    "X_test = ... #complete  \n",
    "X_train = X_train.astype(...) #complete\n",
    "X_test = ... #complete  \n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = ... #complete\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------Deep Nural Network (DNN) -------------------------------------------\n",
    "#----- Part (a) --------------------------------------------------------------------------\n",
    "\n",
    "# Building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(... )) # complete the command\n",
    "model.add(Activation(... )) # complete the command                           \n",
    "\n",
    "model.add(Dense(...)) # complete the command\n",
    "model.add(Activation(...)) # complete the command\n",
    "\n",
    "model.add(Dense(...)) # complete the command\n",
    "model.add(Activation(...)) # complete the command\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------- Compiling the sequential model ---------------------------------\n",
    "\n",
    "sgd = optimizers.SGD(lr= ... , decay= ... , momentum= ... , nesterov= ... ) # complete the command  \n",
    "model.compile(loss='...', metrics=['...'], optimizer= ...) # complete the command  \n",
    "\n",
    "\n",
    "\n",
    "##-------------------------- Training and saving the model ----------------------------------------------\n",
    "start = time.time()\n",
    "\n",
    "## Saving metrics in history\n",
    "\n",
    "# Complete the history: \n",
    "history = model.fit(X_train, Y_train,\n",
    "          epochs= ...,\n",
    "          verbose= ... ,\n",
    "          validation_data=(...))  \n",
    "end = time.time()\n",
    "\n",
    "# saving the model\n",
    "save_dir = \"....\" # Complete\n",
    "model_name = '...' # Complete\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "\n",
    "# plotting the metrics\n",
    "fig = plt.figure()\n",
    "# ----------------------- Plot your result here ---------------------\n",
    "\n",
    "#Plot here\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "## Evaluate the model\n",
    "\n",
    "mnist_model = load_model(model_path)\n",
    "loss_and_metrics = ... #complete  \n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Load the model and create predictions on the test set --------------------\n",
    "mnist_model = load_model(model_path)\n",
    "predicted_classes = mnist_model.predict_classes(X_test)\n",
    "\n",
    "## --------- See which we predicted correctly and which not-----------\n",
    "\n",
    "correct_indices = ... # Complete \n",
    "incorrect_indices = ... # Complete \n",
    "print()\n",
    "print(len(correct_indices),\" classified correctly\")\n",
    "print(len(incorrect_indices),\" classified incorrectly\")\n",
    "\n",
    "# Adapt figure size to accomodate 18 subplots\n",
    "plt.rcParams['figure.figsize'] = (7,6)\n",
    "\n",
    "figure_evaluation = plt.figure()\n",
    "####----------------------------------------- Plot the results----------------\n",
    "# plot 9 correct predictions\n",
    "## plot here....\n",
    "\n",
    "# plot 9 incorrect predictions\n",
    "## plot here...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------- Part (b) -----------------------------------\n",
    "# Repeat part (a) with mini-batch GD and compare the results:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------------------- Part (c) ------------------------------------\n",
    "# Repeat part (a) by fixing \\sum_j N_j and discuss the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------- Part (d) -------------------------------------\n",
    "\n",
    "# Split the dataset to 6 random disjoint subsets, each for one worker, and repeat part (a) on master-worker computational graph.\n",
    "\n",
    "## Prepare the data here:\n",
    "\n",
    "\n",
    "## Compute the weights and DNN layers here:\n",
    "\n",
    "\n",
    "## Complile the sequential model here:\n",
    "\n",
    "\n",
    "## Plotting the metrics here:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------------ Part (e) ---------------------------------\n",
    "\n",
    "# Consider a two-star topology with communication graph (1,2,3,4)-5-6-(7,8,9,10). Repeat part a using your choice of distributed optimization solver. \n",
    "#You can add communication-efficiency to the iterations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------------- Part (f) ---------------------------------\n",
    "\n",
    "# Building a linear stack of layers with the sequential model here:\n",
    "## You can use this command: model.add(Dropout(...))\n",
    "\n",
    "\n",
    "# compiling the sequential model\n",
    "sgd = optimizers.SGD(lr= ... , decay=..., momentum=..., nesterov=...) # complete the command\n",
    "model.compile(loss='categorical_crossentropy', metrics=['...'], optimizer=sgd) # complete the command\n",
    "\n",
    "# Training the model and saving metrics in history here:\n",
    "\n",
    "# saving the model\n",
    "\n",
    "\n",
    "# Plot the results here: \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------------- Part (g) ---------------------------------\n",
    "\n",
    "# Building a linear stack of layers with the sequential model here:\n",
    "## You can use this command: model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# compiling the sequential model\n",
    "sgd = optimizers.SGD(lr= ... , decay=..., momentum=..., nesterov=...) # complete the command\n",
    "model.compile(loss='categorical_crossentropy', metrics=['...'], optimizer=sgd) # complete the command\n",
    "\n",
    "# Training the model and saving metrics in history here:\n",
    "\n",
    "\n",
    "# saving the model:\n",
    "\n",
    "\n",
    "# Plot the results here: \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
